{
    "ggml_tallocr_new": "Creates a new tensor allocator instance.",
    "ggml_tallocr_alloc": "Allocates resources for a tensor allocator instance.",
    "ggml_gallocr_new": "Creates a new graph allocator instance.",
    "ggml_gallocr_new_n": "Creates a new graph allocator instance with a specified count.",
    "ggml_gallocr_free": "Frees a graph allocator instance.",
    "ggml_gallocr_reserve": "Reserves resources for a graph allocator instance.",
    "ggml_gallocr_reserve_n": "Reserves multiple slots for a graph allocator instance.",
    "ggml_gallocr_alloc_graph": "Allocates a computation graph for a graph allocator instance.",
    "ggml_gallocr_get_buffer_size": "Returns the required buffer size for a graph allocator instance.",
    "ggml_backend_alloc_ctx_tensors_from_buft": "Allocates context tensors from a given backend buffer type.",
    "ggml_backend_alloc_ctx_tensors": "Allocates context tensors for the current backend.",
    "ggml_backend_buft_name": "Retrieves the name of a backend buffer type.",
    "ggml_backend_buft_alloc_buffer": "Allocates a buffer for a backend buffer type.",
    "ggml_backend_buft_get_alignment": "Gets the memory alignment for a backend buffer type.",
    "ggml_backend_buft_get_max_size": "Returns the maximum size allowed for a backend buffer type.",
    "ggml_backend_buft_get_alloc_size": "Retrieves the allocation size for a backend buffer type.",
    "ggml_backend_buft_is_host": "Checks if the backend buffer type resides in host memory.",
    "ggml_backend_buft_get_device": "Gets the device associated with a backend buffer type.",
    "ggml_backend_buffer_name": "Retrieves the name of a backend buffer.",
    "ggml_backend_buffer_free": "Frees a previously allocated backend buffer.",
    "ggml_backend_buffer_get_base": "Returns the base pointer of a backend buffer.",
    "ggml_backend_buffer_get_size": "Retrieves the size of a backend buffer.",
    "ggml_backend_buffer_init_tensor": "Initializes a tensor within a backend buffer.",
    "ggml_backend_buffer_get_alignment": "Gets the alignment property of a backend buffer.",
    "ggml_backend_buffer_get_max_size": "Returns the maximum size supported by a backend buffer.",
    "ggml_backend_buffer_get_alloc_size": "Retrieves the allocated size of a backend buffer.",
    "ggml_backend_buffer_clear": "Clears the data stored in a backend buffer.",
    "ggml_backend_buffer_is_host": "Checks if a backend buffer is located in host memory.",
    "ggml_backend_buffer_set_usage": "Sets the usage flags for a backend buffer.",
    "ggml_backend_buffer_get_usage": "Retrieves the usage flags of a backend buffer.",
    "ggml_backend_buffer_get_type": "Returns the type of a backend buffer.",
    "ggml_backend_buffer_reset": "Resets a backend buffer to its initial state.",
    "ggml_backend_tensor_copy": "Copies a tensor using backend operations.",
    "ggml_backend_guid": "Returns the unique identifier for the backend.",
    "ggml_backend_name": "Retrieves the name of the current backend.",
    "ggml_backend_free": "Frees resources associated with the backend.",
    "ggml_backend_get_default_buffer_type": "Returns the default buffer type for the backend.",
    "ggml_backend_alloc_buffer": "Allocates a buffer within the backend.",
    "ggml_backend_get_alignment": "Retrieves the alignment requirement for the backend.",
    "ggml_backend_get_max_size": "Returns the maximum buffer size supported by the backend.",
    "ggml_backend_tensor_set_async": "Enables asynchronous execution for a backend tensor.",
    "ggml_backend_tensor_get_async": "Retrieves the asynchronous status of a backend tensor.",
    "ggml_backend_tensor_set": "Sets properties for a backend tensor.",
    "ggml_backend_tensor_get": "Gets properties of a backend tensor.",
    "ggml_backend_tensor_memset": "Fills a backend tensor with a constant value.",
    "ggml_backend_synchronize": "Synchronizes operations on the backend.",
    "ggml_backend_graph_plan_create": "Creates a computation graph plan for the backend.",
    "ggml_backend_graph_plan_free": "Frees a previously created backend graph plan.",
    "ggml_backend_graph_plan_compute": "Executes a computation graph plan on the backend.",
    "ggml_backend_graph_compute": "Computes a graph on the backend synchronously.",
    "ggml_backend_graph_compute_async": "Initiates asynchronous graph computation on the backend.",
    "ggml_backend_supports_op": "Checks if the backend supports a specific operation.",
    "ggml_backend_supports_buft": "Verifies if the backend supports a specific buffer type.",
    "ggml_backend_offload_op": "Offloads an operation to a backend device.",
    "ggml_backend_tensor_copy_async": "Asynchronously copies a tensor using the backend.",
    "ggml_backend_get_device": "Retrieves the current device used by the backend.",
    "ggml_backend_event_new": "Creates a new event for backend synchronization.",
    "ggml_backend_event_free": "Frees a backend event.",
    "ggml_backend_event_record": "Records a timestamp in a backend event.",
    "ggml_backend_event_synchronize": "Synchronizes a backend event.",
    "ggml_backend_event_wait": "Waits for a backend event to complete.",
    "ggml_backend_dev_name": "Returns the name of a backend device.",
    "ggml_backend_dev_description": "Retrieves the description of a backend device.",
    "ggml_backend_dev_memory": "Returns the memory capacity of a backend device.",
    "ggml_backend_dev_type": "Retrieves the type of a backend device.",
    "ggml_backend_dev_get_props": "Gets the properties of a backend device.",
    "ggml_backend_dev_backend_reg": "Retrieves the registry entry for a backend device.",
    "ggml_backend_dev_init": "Initializes a backend device.",
    "ggml_backend_dev_buffer_type": "Returns the buffer type used by a backend device.",
    "ggml_backend_dev_host_buffer_type": "Returns the host buffer type for a backend device.",
    "ggml_backend_dev_buffer_from_host_ptr": "Creates a device buffer from a host pointer.",
    "ggml_backend_dev_supports_op": "Checks if a backend device supports a specific operation.",
    "ggml_backend_dev_supports_buft": "Verifies if a backend device supports a buffer type.",
    "ggml_backend_dev_offload_op": "Offloads an operation specifically to a backend device.",
    "ggml_backend_reg_name": "Retrieves the name of a backend registry.",
    "ggml_backend_reg_dev_count": "Returns the number of devices in a backend registry.",
    "ggml_backend_reg_dev_get": "Gets a device from the backend registry by index.",
    "ggml_backend_reg_get_proc_address": "Retrieves a procedure address from the backend registry.",
    "ggml_backend_device_register": "Registers a new device with the backend.",
    "ggml_backend_reg_count": "Returns the total count of backend registries.",
    "ggml_backend_reg_get": "Retrieves an entry from the backend registry.",
    "ggml_backend_reg_by_name": "Finds a backend registry entry by name.",
    "ggml_backend_dev_count": "Returns the number of available backend devices.",
    "ggml_backend_dev_get": "Retrieves a backend device by index.",
    "ggml_backend_dev_by_name": "Finds a backend device by its name.",
    "ggml_backend_dev_by_type": "Finds a backend device by its type.",
    "ggml_backend_init_by_name": "Initializes the backend using its name.",
    "ggml_backend_init_by_type": "Initializes the backend based on device type.",
    "ggml_backend_init_best": "Initializes the best available backend automatically.",
    "ggml_backend_load": "Loads a backend module.",
    "ggml_backend_unload": "Unloads a backend module.",
    "ggml_backend_load_all": "Loads all available backend modules.",
    "ggml_backend_load_all_from_path": "Loads all backend modules from a specified path.",
    "ggml_backend_sched_new": "Creates a new scheduler for backend operations.",
    "ggml_backend_sched_free": "Frees a backend scheduler.",
    "ggml_backend_sched_reserve": "Reserves resources within the backend scheduler.",
    "ggml_backend_sched_get_n_backends": "Returns the number of backends managed by the scheduler.",
    "ggml_backend_sched_get_backend": "Retrieves a specific backend from the scheduler.",
    "ggml_backend_sched_get_n_splits": "Gets the number of splits configured in the scheduler.",
    "ggml_backend_sched_get_n_copies": "Returns the number of tensor copies scheduled.",
    "ggml_backend_sched_get_buffer_size": "Retrieves the buffer size allocated by the scheduler.",
    "ggml_backend_sched_set_tensor_backend": "Assigns a tensor to a specific backend in the scheduler.",
    "ggml_backend_sched_get_tensor_backend": "Retrieves the backend associated with a tensor in the scheduler.",
    "ggml_backend_sched_alloc_graph": "Allocates a computation graph for the scheduler.",
    "ggml_backend_sched_graph_compute": "Computes a graph using the scheduler synchronously.",
    "ggml_backend_sched_graph_compute_async": "Initiates asynchronous graph computation via the scheduler.",
    "ggml_backend_sched_synchronize": "Synchronizes all scheduled backend operations.",
    "ggml_backend_sched_reset": "Resets the state of the backend scheduler.",
    "ggml_backend_sched_set_eval_callback": "Sets an evaluation callback function in the scheduler.",
    "ggml_backend_graph_copy": "Creates a duplicate of a backend computation graph.",
    "ggml_backend_graph_copy_free": "Frees a duplicated backend graph.",
    "ggml_backend_compare_graph_backend": "Compares two backend graph implementations.",
    "ggml_backend_tensor_alloc": "Allocates memory for a new backend tensor.",
    "ggml_backend_view_init": "Initializes a tensor view for the backend.",
    "ggml_backend_cpu_buffer_from_ptr": "Creates a CPU backend buffer from an existing pointer.",
    "ggml_backend_cpu_buffer_type": "Returns the buffer type used by the CPU backend.",
    "ggml_backend_blas_init": "Initializes the BLAS (Basic Linear Algebra Subprograms) backend.",
    "ggml_backend_is_blas": "Checks if the BLAS backend is active.",
    "ggml_backend_blas_set_n_threads": "Sets the number of threads for BLAS operations.",
    "ggml_backend_blas_reg": "Registers the BLAS backend.",
    "ggml_backend_cann_reg": "Registers the CANN backend.",
    "ggml_backend_cann_init": "Initializes the CANN backend.",
    "ggml_backend_is_cann": "Checks if the CANN backend is active.",
    "ggml_backend_cann_buffer_type": "Returns the buffer type for the CANN backend.",
    "ggml_backend_cann_get_device_count": "Returns the number of CANN devices available.",
    "ggml_backend_cann_host_buffer_type": "Returns the host buffer type for the CANN backend.",
    "ggml_backend_cann_get_device_description": "Retrieves the description of a CANN device.",
    "ggml_backend_cann_get_device_memory": "Returns the memory capacity of a CANN device.",
    "ggml_numa_init": "Initializes NUMA (Non-Uniform Memory Access) support.",
    "ggml_is_numa": "Checks if NUMA is enabled.",
    "ggml_new_i32": "Creates a new 32-bit integer tensor.",
    "ggml_new_f32": "Creates a new 32-bit floating-point tensor.",
    "ggml_set_i32": "Sets the value of a 32-bit integer tensor.",
    "ggml_set_f32": "Sets the value of a 32-bit floating-point tensor.",
    "ggml_get_i32_1d": "Retrieves one-dimensional data from a 32-bit integer tensor.",
    "ggml_set_i32_1d": "Sets one-dimensional data for a 32-bit integer tensor.",
    "ggml_get_i32_nd": "Retrieves N-dimensional data from a 32-bit integer tensor.",
    "ggml_set_i32_nd": "Sets N-dimensional data for a 32-bit integer tensor.",
    "ggml_get_f32_1d": "Retrieves one-dimensional data from a 32-bit floating-point tensor.",
    "ggml_set_f32_1d": "Sets one-dimensional data for a 32-bit floating-point tensor.",
    "ggml_get_f32_nd": "Retrieves N-dimensional data from a 32-bit floating-point tensor.",
    "ggml_set_f32_nd": "Sets N-dimensional data for a 32-bit floating-point tensor.",
    "ggml_threadpool_new": "Creates a new thread pool for parallel operations.",
    "ggml_threadpool_free": "Frees a previously created thread pool.",
    "ggml_threadpool_get_n_threads": "Returns the number of threads in the thread pool.",
    "ggml_threadpool_pause": "Pauses execution of the thread pool.",
    "ggml_threadpool_resume": "Resumes execution of the thread pool.",
    "ggml_graph_plan": "Plans the execution order of a computation graph.",
    "ggml_graph_compute": "Executes the computation graph.",
    "ggml_graph_compute_with_ctx": "Computes a graph with an associated execution context.",
    "ggml_cpu_has_sse3": "Checks if the CPU supports SSE3 instructions.",
    "ggml_cpu_has_ssse3": "Checks if the CPU supports SSSE3 instructions.",
    "ggml_cpu_has_avx": "Checks if the CPU supports AVX instructions.",
    "ggml_cpu_has_avx_vnni": "Checks if the CPU supports AVX VNNI instructions.",
    "ggml_cpu_has_avx2": "Checks if the CPU supports AVX2 instructions.",
    "ggml_cpu_has_f16c": "Checks if the CPU supports F16C instructions.",
    "ggml_cpu_has_fma": "Checks if the CPU supports FMA (Fused Multiply-Add) instructions.",
    "ggml_cpu_has_avx512": "Checks if the CPU supports AVX512 instructions.",
    "ggml_cpu_has_avx512_vbmi": "Checks if the CPU supports AVX512 VBMI instructions.",
    "ggml_cpu_has_avx512_vnni": "Checks if the CPU supports AVX512 VNNI instructions.",
    "ggml_cpu_has_avx512_bf16": "Checks if the CPU supports AVX512 BF16 instructions.",
    "ggml_cpu_has_amx_int8": "Checks if the CPU supports AMX INT8 instructions.",
    "ggml_cpu_has_neon": "Checks if the CPU supports NEON instructions.",
    "ggml_cpu_has_arm_fma": "Checks if the CPU supports ARM FMA instructions.",
    "ggml_cpu_has_fp16_va": "Checks if the CPU supports FP16 vector arithmetic.",
    "ggml_cpu_has_dotprod": "Checks if the CPU supports dot product operations.",
    "ggml_cpu_has_matmul_int8": "Checks if the CPU supports int8 matrix multiplication.",
    "ggml_cpu_has_sve": "Checks if the CPU supports SVE (Scalable Vector Extension).",
    "ggml_cpu_get_sve_cnt": "Returns the number of SVE registers available on the CPU.",
    "ggml_cpu_has_riscv_v": "Checks if a RISC-V CPU supports vector instructions.",
    "ggml_cpu_has_vsx": "Checks if the CPU supports VSX instructions.",
    "ggml_cpu_has_wasm_simd": "Checks if the CPU supports WebAssembly SIMD.",
    "ggml_cpu_has_llamafile": "Checks if the CPU supports llama file optimizations.",
    "ggml_get_type_traits_cpu": "Retrieves CPU type traits for tensor operations.",
    "ggml_cpu_init": "Initializes CPU-specific settings for ggml.",
    "ggml_backend_cpu_init": "Initializes the CPU backend.",
    "ggml_backend_is_cpu": "Checks if the active backend is CPU-based.",
    "ggml_backend_cpu_set_n_threads": "Sets the number of threads for the CPU backend.",
    "ggml_backend_cpu_set_threadpool": "Assigns a thread pool to the CPU backend.",
    "ggml_backend_cpu_set_abort_callback": "Sets an abort callback for CPU backend operations.",
    "ggml_backend_cpu_reg": "Registers the CPU backend.",
    "ggml_backend_cuda_init": "Initializes the CUDA backend.",
    "ggml_backend_is_cuda": "Checks if the active backend is CUDA.",
    "ggml_backend_cuda_buffer_type": "Returns the buffer type for the CUDA backend.",
    "ggml_backend_cuda_split_buffer_type": "Returns the split buffer type for CUDA operations.",
    "ggml_backend_cuda_host_buffer_type": "Returns the host buffer type for the CUDA backend.",
    "ggml_backend_cuda_get_device_count": "Returns the number of available CUDA devices.",
    "ggml_backend_cuda_get_device_description": "Retrieves the description of a CUDA device.",
    "ggml_backend_cuda_get_device_memory": "Returns the memory capacity of a CUDA device.",
    "ggml_backend_cuda_register_host_buffer": "Registers a host buffer with the CUDA backend.",
    "ggml_backend_cuda_unregister_host_buffer": "Unregisters a host buffer from the CUDA backend.",
    "ggml_backend_cuda_reg": "Registers the CUDA backend.",
    "ggml_vk_available_devices": "Lists the available Vulkan devices.",
    "ggml_vk_get_device": "Retrieves a Vulkan device by index.",
    "ggml_vk_has_vulkan": "Checks if Vulkan is supported on the system.",
    "ggml_vk_has_device": "Checks if a specific Vulkan device is available.",
    "ggml_vk_current_device": "Returns the currently active Vulkan device.",
    "ggml_backend_kompute_init": "Initializes the Kompute backend.",
    "ggml_backend_is_kompute": "Checks if the active backend is Kompute.",
    "ggml_backend_kompute_buffer_type": "Returns the buffer type for the Kompute backend.",
    "ggml_backend_kompute_reg": "Registers the Kompute backend.",
    "ggml_backend_metal_init": "Initializes the Metal backend.",
    "ggml_backend_is_metal": "Checks if the active backend is Metal.",
    "ggml_backend_metal_buffer_from_ptr": "Creates a Metal buffer from a host pointer.",
    "ggml_backend_metal_set_abort_callback": "Sets an abort callback for Metal operations.",
    "ggml_backend_metal_buffer_type": "Returns the buffer type for the Metal backend.",
    "ggml_backend_metal_supports_family": "Checks if the Metal backend supports a specific family.",
    "ggml_backend_metal_capture_next_compute": "Captures the next compute command in Metal.",
    "ggml_backend_metal_reg": "Registers the Metal backend.",
    "ggml_backend_opencl_init": "Initializes the OpenCL backend.",
    "ggml_backend_is_opencl": "Checks if the active backend is OpenCL.",
    "ggml_backend_opencl_buffer_type": "Returns the buffer type for the OpenCL backend.",
    "ggml_backend_opencl_host_buffer_type": "Returns the host buffer type for OpenCL.",
    "ggml_backend_opencl_reg": "Registers the OpenCL backend.",
    "ggml_opt_dataset_init": "Initializes an optimization dataset.",
    "ggml_opt_dataset_free": "Frees an optimization dataset.",
    "ggml_opt_dataset_data": "Retrieves the data from an optimization dataset.",
    "ggml_opt_dataset_labels": "Retrieves the labels from an optimization dataset.",
    "ggml_opt_dataset_shuffle": "Shuffles the entries in an optimization dataset.",
    "ggml_opt_dataset_get_batch": "Gets a batch of data from an optimization dataset.",
    "ggml_opt_get_default_optimizer_params": "Retrieves the default parameters for the optimizer.",
    "ggml_opt_default_params": "Returns default optimization parameters.",
    "ggml_opt_init": "Initializes an optimizer instance.",
    "ggml_opt_free": "Frees an optimizer instance.",
    "ggml_opt_reset": "Resets the optimizer to its initial state.",
    "ggml_opt_inputs": "Retrieves the input tensors for the optimizer.",
    "ggml_opt_outputs": "Retrieves the output tensors for the optimizer.",
    "ggml_opt_labels": "Retrieves the label tensors used in optimization.",
    "ggml_opt_loss": "Returns the computed loss from the optimizer.",
    "ggml_opt_pred": "Retrieves prediction outputs from the optimizer.",
    "ggml_opt_ncorrect": "Returns the number of correct predictions.",
    "ggml_opt_grad_acc": "Retrieves the accumulated gradients from the optimizer.",
    "ggml_opt_result_init": "Initializes a structure for storing optimizer results.",
    "ggml_opt_result_free": "Frees an optimizer result structure.",
    "ggml_opt_result_reset": "Resets the optimizer result structure.",
    "ggml_opt_result_ndata": "Returns the number of data points in the optimizer results.",
    "ggml_opt_result_loss": "Retrieves the loss value from the optimizer results.",
    "ggml_opt_result_pred": "Retrieves predictions from the optimizer results.",
    "ggml_opt_result_accuracy": "Calculates accuracy from the optimizer results.",
    "ggml_opt_forward": "Performs a forward pass using the optimizer.",
    "ggml_opt_forward_backward": "Performs both forward and backward passes in optimization.",
    "ggml_opt_epoch": "Executes one optimization epoch.",
    "ggml_opt_epoch_callback_progress_bar": "Updates a progress bar during an optimization epoch.",
    "ggml_opt_fit": "Trains a model using the optimizer.",
    "ggml_backend_rpc_init": "Initializes the RPC backend.",
    "ggml_backend_is_rpc": "Checks if the active backend is RPC.",
    "ggml_backend_rpc_buffer_type": "Returns the buffer type for the RPC backend.",
    "ggml_backend_rpc_get_device_memory": "Returns the device memory for an RPC backend device.",
    "ggml_backend_rpc_start_server": "Starts an RPC server for backend communication.",
    "ggml_backend_rpc_reg": "Registers the RPC backend.",
    "ggml_backend_rpc_add_device": "Adds a device to the RPC backend.",
    "ggml_backend_sycl_init": "Initializes the SYCL backend.",
    "ggml_backend_is_sycl": "Checks if the active backend is SYCL.",
    "ggml_backend_sycl_buffer_type": "Returns the buffer type for the SYCL backend.",
    "ggml_backend_sycl_split_buffer_type": "Returns the split buffer type for SYCL operations.",
    "ggml_backend_sycl_host_buffer_type": "Returns the host buffer type for the SYCL backend.",
    "ggml_backend_sycl_print_sycl_devices": "Prints available SYCL devices.",
    "ggml_backend_sycl_get_gpu_list": "Retrieves a list of SYCL GPU devices.",
    "ggml_backend_sycl_get_device_description": "Gets the description of a SYCL device.",
    "ggml_backend_sycl_get_device_count": "Returns the number of available SYCL devices.",
    "ggml_backend_sycl_get_device_memory": "Returns the memory capacity of a SYCL device.",
    "ggml_backend_sycl_reg": "Registers the SYCL backend.",
    "ggml_backend_vk_init": "Initializes the Vulkan backend.",
    "ggml_backend_is_vk": "Checks if the active backend is Vulkan.",
    "ggml_backend_vk_get_device_count": "Returns the number of available Vulkan devices.",
    "ggml_backend_vk_get_device_description": "Retrieves the description of a Vulkan device.",
    "ggml_backend_vk_get_device_memory": "Returns the memory capacity of a Vulkan device.",
    "ggml_backend_vk_buffer_type": "Returns the buffer type for the Vulkan backend.",
    "ggml_backend_vk_host_buffer_type": "Returns the host buffer type for the Vulkan backend.",
    "ggml_backend_vk_reg": "Registers the Vulkan backend.",
    "ggml_abort": "Aborts the current ggml operation.",
    "ggml_status_to_string": "Converts a ggml status code to a human-readable string.",
    "ggml_fp16_to_fp32": "Converts half-precision floats to single-precision.",
    "ggml_fp32_to_fp16": "Converts single-precision floats to half-precision.",
    "ggml_fp16_to_fp32_row": "Converts a row of half-precision floats to single-precision.",
    "ggml_fp32_to_fp16_row": "Converts a row of single-precision floats to half-precision.",
    "ggml_fp32_to_bf16": "Converts single-precision floats to bfloat16 format.",
    "ggml_bf16_to_fp32": "Converts bfloat16 values to single-precision floats.",
    "ggml_bf16_to_fp32_row": "Converts a row of bfloat16 values to single-precision.",
    "ggml_fp32_to_bf16_row_ref": "Converts a reference row of single-precision floats to bfloat16.",
    "ggml_fp32_to_bf16_row": "Converts a row of single-precision floats to bfloat16.",
    "ggml_guid_matches": "Checks if two GUIDs match.",
    "ggml_time_init": "Initializes the ggml timing system.",
    "ggml_time_ms": "Returns the current time in milliseconds.",
    "ggml_time_us": "Returns the current time in microseconds.",
    "ggml_cycles": "Returns the current CPU cycle count.",
    "ggml_cycles_per_ms": "Calculates the number of CPU cycles per millisecond.",
    "ggml_fopen": "Opens a file with ggml-specific settings.",
    "ggml_print_object": "Prints detailed information of a ggml object.",
    "ggml_print_objects": "Prints details of multiple ggml objects.",
    "ggml_nelements": "Returns the number of elements in a tensor.",
    "ggml_nrows": "Returns the number of rows in a tensor.",
    "ggml_nbytes": "Returns the total number of bytes occupied by a tensor.",
    "ggml_nbytes_pad": "Returns the padded byte size of a tensor.",
    "ggml_blck_size": "Returns the block size used in tensor operations.",
    "ggml_type_size": "Returns the size in bytes of a tensor type.",
    "ggml_row_size": "Returns the size of a tensor row in bytes.",
    "ggml_type_sizef": "Returns the floating-point size in bytes for a tensor type.",
    "ggml_type_name": "Returns the name of a tensor type.",
    "ggml_op_name": "Returns the name of an operation.",
    "ggml_op_symbol": "Returns the symbol representing an operation.",
    "ggml_unary_op_name": "Returns the name of a unary operation.",
    "ggml_op_desc": "Provides a description of an operation.",
    "ggml_element_size": "Returns the size in bytes of a single tensor element.",
    "ggml_is_quantized": "Checks if a tensor is quantized.",
    "ggml_ftype_to_ggml_type": "Converts a file type to a ggml tensor type.",
    "ggml_is_transposed": "Checks if a tensor has been transposed.",
    "ggml_is_permuted": "Checks if a tensor's dimensions are permuted.",
    "ggml_is_empty": "Checks if a tensor contains no data.",
    "ggml_is_scalar": "Checks if a tensor represents a scalar.",
    "ggml_is_vector": "Checks if a tensor is a vector.",
    "ggml_is_matrix": "Checks if a tensor is a matrix.",
    "ggml_is_3d": "Checks if a tensor is three-dimensional.",
    "ggml_n_dims": "Returns the number of dimensions of a tensor.",
    "ggml_is_contiguous": "Checks if a tensor is stored contiguously in memory.",
    "ggml_is_contiguous_0": "Checks if the first dimension of a tensor is contiguous.",
    "ggml_is_contiguous_1": "Checks if the second dimension of a tensor is contiguous.",
    "ggml_is_contiguous_2": "Checks if the third dimension of a tensor is contiguous.",
    "ggml_are_same_shape": "Checks if two tensors have identical shapes.",
    "ggml_are_same_stride": "Checks if two tensors have identical memory strides.",
    "ggml_can_repeat": "Checks if a tensor can be repeated along its dimensions.",
    "ggml_tensor_overhead": "Returns the memory overhead of a tensor.",
    "ggml_validate_row_data": "Validates the data contained in a tensor row.",
    "ggml_init": "Creates a ggml_context.",
    "ggml_reset": "Resets the internal state of ggml.",
    "ggml_free": "Frees resources allocated by ggml.",
    "ggml_used_mem": "Returns the amount of memory currently used by ggml.",
    "ggml_get_no_alloc": "Checks if memory allocation is disabled in ggml.",
    "ggml_set_no_alloc": "Sets the flag to disable memory allocation in ggml.",
    "ggml_get_mem_buffer": "Retrieves the current memory buffer pointer used by ggml.",
    "ggml_get_mem_size": "Returns the size of the allocated memory buffer in ggml.",
    "ggml_get_max_tensor_size": "Returns the maximum allowable size for a tensor.",
    "ggml_new_tensor": "Creates a new tensor with specified parameters.",
    "ggml_new_tensor_1d": "Creates a new one-dimensional tensor.",
    "ggml_new_tensor_2d": "Creates a new two-dimensional tensor.",
    "ggml_new_tensor_3d": "Creates a new three-dimensional tensor.",
    "ggml_new_tensor_4d": "Creates a new four-dimensional tensor.",
    "ggml_new_buffer": "Creates a new memory buffer for tensor operations.",
    "ggml_dup_tensor": "Duplicates an existing tensor.",
    "ggml_view_tensor": "Creates a view into an existing tensor.",
    "ggml_get_first_tensor": "Retrieves the first tensor in a tensor list.",
    "ggml_get_next_tensor": "Retrieves the next tensor in a tensor list.",
    "ggml_get_tensor": "Retrieves a tensor by its index or identifier.",
    "ggml_unravel_index": "Converts a flat index into multi-dimensional indices.",
    "ggml_get_unary_op": "Retrieves a unary operation function.",
    "ggml_get_data": "Returns a pointer to the raw data of a tensor.",
    "ggml_get_data_f32": "Returns a pointer to the float data of a tensor.",
    "ggml_get_name": "Retrieves the name of a tensor.",
    "ggml_set_name": "Assigns a name to a tensor.",
    "ggml_format_name": "Formats a tensor name for display purposes.",
    "ggml_set_input": "Marks a tensor as an input for computations.",
    "ggml_set_output": "Marks a tensor as an output for computations.",
    "ggml_set_param": "Sets a parameter for a tensor or operation.",
    "ggml_set_loss": "Sets the loss value for optimization purposes.",
    "ggml_dup": "Duplicates a tensor (shallow copy).",
    "ggml_dup_inplace": "Duplicates a tensor in-place.",
    "ggml_add": "Adds two tensors element-wise.",
    "ggml_add_inplace": "Adds one tensor to another in-place.",
    "ggml_add_cast": "Performs tensor addition with type casting.",
    "ggml_add1": "Adds a scalar value to a tensor.",
    "ggml_add1_inplace": "Adds a scalar value to a tensor in-place.",
    "ggml_acc": "Accumulates values from one tensor into another.",
    "ggml_acc_inplace": "Accumulates tensor values in-place.",
    "ggml_sub": "Subtracts one tensor from another element-wise.",
    "ggml_sub_inplace": "Subtracts one tensor from another in-place.",
    "ggml_mul": "Multiplies two tensors element-wise.",
    "ggml_mul_inplace": "Multiplies two tensors element-wise in-place.",
    "ggml_div": "Divides one tensor by another element-wise.",
    "ggml_div_inplace": "Divides one tensor by another in-place.",
    "ggml_sqr": "Squares each element of a tensor.",
    "ggml_sqr_inplace": "Squares each tensor element in-place.",
    "ggml_sqrt": "Computes the square root of each tensor element.",
    "ggml_sqrt_inplace": "Computes square roots of tensor elements in-place.",
    "ggml_log": "Computes the natural logarithm of each tensor element.",
    "ggml_log_inplace": "Computes natural logarithms in-place on a tensor.",
    "ggml_sin": "Computes the sine of each tensor element.",
    "ggml_sin_inplace": "Computes sine in-place on a tensor.",
    "ggml_cos": "Computes the cosine of each tensor element.",
    "ggml_cos_inplace": "Computes cosine in-place on a tensor.",
    "ggml_sum": "Sums all elements of a tensor.",
    "ggml_sum_rows": "Sums the elements across each row of a tensor.",
    "ggml_mean": "Computes the mean value of a tensor.",
    "ggml_argmax": "Finds the index of the maximum element in a tensor.",
    "ggml_count_equal": "Counts elements equal to a specified value in a tensor.",
    "ggml_repeat": "Repeats a tensor along specified dimensions.",
    "ggml_repeat_back": "Repeats a tensor in reverse along specified dimensions.",
    "ggml_concat": "Concatenates multiple tensors along a given dimension.",
    "ggml_abs": "Computes the absolute value of each tensor element.",
    "ggml_abs_inplace": "Computes absolute values in-place on a tensor.",
    "ggml_sgn": "Computes the sign of each tensor element.",
    "ggml_sgn_inplace": "Computes the sign in-place on a tensor.",
    "ggml_neg": "Negates each element of a tensor.",
    "ggml_neg_inplace": "Negates tensor elements in-place.",
    "ggml_step": "Applies a step function to a tensor.",
    "ggml_step_inplace": "Applies a step function in-place on a tensor.",
    "ggml_tanh": "Computes the hyperbolic tangent of each tensor element.",
    "ggml_tanh_inplace": "Computes hyperbolic tangent in-place on a tensor.",
    "ggml_elu": "Applies the ELU activation function to a tensor.",
    "ggml_elu_inplace": "Applies the ELU activation function in-place on a tensor.",
    "ggml_relu": "Applies the ReLU activation function to a tensor.",
    "ggml_leaky_relu": "Applies the Leaky ReLU activation function to a tensor.",
    "ggml_relu_inplace": "Applies the ReLU activation function in-place on a tensor.",
    "ggml_sigmoid": "Applies the sigmoid activation function to a tensor.",
    "ggml_sigmoid_inplace": "Applies the sigmoid activation function in-place on a tensor.",
    "ggml_gelu": "Applies the GELU activation function to a tensor.",
    "ggml_gelu_inplace": "Applies the GELU activation function in-place on a tensor.",
    "ggml_gelu_quick": "Applies a fast approximation of the GELU activation.",
    "ggml_gelu_quick_inplace": "Applies a fast GELU approximation in-place on a tensor.",
    "ggml_silu": "Applies the SiLU (swish) activation function to a tensor.",
    "ggml_silu_inplace": "Applies the SiLU activation function in-place on a tensor.",
    "ggml_silu_back": "Computes the backward pass for the SiLU activation.",
    "ggml_hardswish": "Applies the hard-swish activation function to a tensor.",
    "ggml_hardsigmoid": "Applies the hard-sigmoid activation function to a tensor.",
    "ggml_exp": "Computes the exponential of each tensor element.",
    "ggml_exp_inplace": "Computes exponentials in-place on a tensor.",
    "ggml_norm": "Normalizes the elements of a tensor.",
    "ggml_norm_inplace": "Normalizes a tensor in-place.",
    "ggml_rms_norm": "Applies RMS normalization to a tensor.",
    "ggml_rms_norm_inplace": "Applies RMS normalization in-place on a tensor.",
    "ggml_group_norm": "Applies group normalization to a tensor.",
    "ggml_group_norm_inplace": "Applies group normalization in-place on a tensor.",
    "ggml_rms_norm_back": "Computes the backward pass for RMS normalization.",
    "ggml_mul_mat": "Performs matrix multiplication between two tensors.",
    "ggml_mul_mat_set_prec": "Performs matrix multiplication with specified precision.",
    "ggml_mul_mat_id": "Performs matrix multiplication incorporating an identity adjustment.",
    "ggml_out_prod": "Computes the outer product of two tensors.",
    "ggml_scale": "Scales a tensor by a constant factor.",
    "ggml_scale_inplace": "Scales a tensor in-place by a constant factor.",
    "ggml_set": "Sets tensor elements to specified values.",
    "ggml_set_inplace": "Sets tensor elements in-place to specified values.",
    "ggml_set_1d": "Sets elements of a one-dimensional tensor.",
    "ggml_set_1d_inplace": "Sets one-dimensional tensor elements in-place.",
    "ggml_set_2d": "Sets elements of a two-dimensional tensor.",
    "ggml_set_2d_inplace": "Sets two-dimensional tensor elements in-place.",
    "ggml_cpy": "Copies data from one tensor to another.",
    "ggml_cast": "Casts a tensor to a different data type.",
    "ggml_cont": "Ensures a tensor is stored contiguously in memory.",
    "ggml_cont_1d": "Ensures a one-dimensional tensor is contiguous in memory.",
    "ggml_cont_2d": "Ensures a two-dimensional tensor is contiguous in memory.",
    "ggml_cont_3d": "Ensures a three-dimensional tensor is contiguous in memory.",
    "ggml_cont_4d": "Ensures a four-dimensional tensor is contiguous in memory.",
    "ggml_reshape": "Reshapes a tensor to new dimensions.",
    "ggml_reshape_1d": "Reshapes a tensor into one dimension.",
    "ggml_reshape_2d": "Reshapes a tensor into two dimensions.",
    "ggml_reshape_3d": "Reshapes a tensor into three dimensions.",
    "ggml_reshape_4d": "Reshapes a tensor into four dimensions.",
    "ggml_view_1d": "Creates a one-dimensional view of a tensor.",
    "ggml_view_2d": "Creates a two-dimensional view of a tensor.",
    "ggml_view_3d": "Creates a three-dimensional view of a tensor.",
    "ggml_view_4d": "Creates a four-dimensional view of a tensor.",
    "ggml_permute": "Permutes the dimensions of a tensor.",
    "ggml_transpose": "Transposes a tensor.",
    "ggml_get_rows": "Retrieves specific rows from a tensor.",
    "ggml_get_rows_back": "Retrieves rows from a tensor in reverse order.",
    "ggml_diag": "Extracts the diagonal elements of a tensor.",
    "ggml_diag_mask_inf": "Masks the diagonal of a tensor with negative infinity.",
    "ggml_diag_mask_inf_inplace": "Masks the diagonal with negative infinity in-place.",
    "ggml_diag_mask_zero": "Masks the diagonal of a tensor with zero.",
    "ggml_diag_mask_zero_inplace": "Masks the diagonal with zero in-place.",
    "ggml_soft_max": "Applies the softmax function to a tensor.",
    "ggml_soft_max_inplace": "Applies the softmax function in-place on a tensor.",
    "ggml_soft_max_ext": "Applies an extended softmax function to a tensor.",
    "ggml_soft_max_ext_back": "Computes the backward pass for the extended softmax.",
    "ggml_soft_max_ext_back_inplace": "Computes the backward pass for extended softmax in-place.",
    "ggml_rope": "Applies rotary positional embedding to a tensor.",
    "ggml_rope_inplace": "Applies rotary positional embedding in-place on a tensor.",
    "ggml_rope_ext": "Applies an extended version of rotary positional embedding.",
    "ggml_rope_multi": "Applies rotary embedding to multiple tensors simultaneously.",
    "ggml_rope_ext_inplace": "Applies extended rotary positional embedding in-place.",
    "ggml_rope_custom": "Applies a custom rotary positional embedding to a tensor.",
    "ggml_rope_custom_inplace": "Applies a custom rotary embedding in-place.",
    "ggml_rope_yarn_corr_dims": "Adjusts dimensions for rotary embeddings in specialized correlators.",
    "ggml_rope_ext_back": "Computes the backward pass for extended rotary embedding.",
    "ggml_rope_multi_back": "Computes the backward pass for multiple rotary embeddings.",
    "ggml_clamp": "Clamps tensor values between a minimum and maximum.",
    "ggml_im2col": "Transforms image data into a columnar matrix format.",
    "ggml_im2col_back": "Reconstructs image data from its columnar representation.",
    "ggml_conv_1d": "Performs a one-dimensional convolution operation.",
    "ggml_conv_1d_ph": "Performs a phase-based one-dimensional convolution.",
    "ggml_conv_1d_dw": "Performs a depthwise one-dimensional convolution.",
    "ggml_conv_1d_dw_ph": "Performs a phase-based depthwise one-dimensional convolution.",
    "ggml_conv_transpose_1d": "Performs a transposed one-dimensional convolution.",
    "ggml_conv_2d": "Performs a two-dimensional convolution operation.",
    "ggml_conv_2d_sk_p0": "Performs a two-dimensional convolution with stride kernel padding of 0.",
    "ggml_conv_2d_s1_ph": "Performs a phase-based two-dimensional convolution with stride 1.",
    "ggml_conv_2d_dw": "Performs a depthwise two-dimensional convolution.",
    "ggml_conv_transpose_2d_p0": "Performs a transposed two-dimensional convolution with padding 0.",
    "ggml_pool_1d": "Performs a one-dimensional pooling operation.",
    "ggml_pool_2d": "Performs a two-dimensional pooling operation.",
    "ggml_pool_2d_back": "Computes the backward pass for a two-dimensional pooling operation.",
    "ggml_upscale": "Upscales a tensor by a specified factor.",
    "ggml_upscale_ext": "Upscales a tensor with extended options.",
    "ggml_pad": "Pads a tensor with a specified value.",
    "ggml_pad_reflect_1d": "Pads a one-dimensional tensor using reflection.",
    "ggml_timestep_embedding": "Generates timestep embeddings for a tensor.",
    "ggml_argsort": "Returns indices that sort the tensor.",
    "ggml_arange": "Generates a tensor with sequential values.",
    "ggml_top_k": "Selects the top k elements from a tensor.",
    "ggml_flash_attn_ext": "Performs an extended flash attention operation.",
    "ggml_flash_attn_ext_set_prec": "Sets the precision for extended flash attention.",
    "ggml_flash_attn_ext_get_prec": "Gets the current precision setting for extended flash attention.",
    "ggml_flash_attn_back": "Computes the backward pass for flash attention.",
    "ggml_ssm_conv": "Performs a state-space model convolution.",
    "ggml_ssm_scan": "Performs a state-space model scan operation.",
    "ggml_win_part": "Partitions a tensor into windows.",
    "ggml_win_unpart": "Reassembles a tensor from its window partitions.",
    "ggml_unary": "Applies a unary function to all tensor elements.",
    "ggml_unary_inplace": "Applies a unary function to a tensor in-place.",
    "ggml_get_rel_pos": "Retrieves relative positional information from a tensor.",
    "ggml_add_rel_pos": "Adds relative positional embeddings to a tensor.",
    "ggml_add_rel_pos_inplace": "Adds relative positional embeddings in-place to a tensor.",
    "ggml_rwkv_wkv6": "Computes the RWKV WKV6 operation on a tensor.",
    "ggml_gated_linear_attn": "Applies gated linear attention to a tensor.",
    "ggml_map_unary_f32": "Maps a unary function over a float tensor.",
    "ggml_map_unary_inplace_f32": "Applies a unary function to a float tensor in-place.",
    "ggml_map_binary_f32": "Applies a binary function to two float tensors.",
    "ggml_map_binary_inplace_f32": "Applies a binary function in-place on two float tensors.",
    "ggml_map_custom1_f32": "Applies a custom unary function on a float tensor.",
    "ggml_map_custom1_inplace_f32": "Applies a custom unary function on a float tensor in-place.",
    "ggml_map_custom2_f32": "Applies a custom binary function on a float tensor.",
    "ggml_map_custom2_inplace_f32": "Applies a custom binary function on a float tensor in-place.",
    "ggml_map_custom3_f32": "Applies a custom ternary function on a float tensor.",
    "ggml_map_custom3_inplace_f32": "Applies a custom ternary function on a float tensor in-place.",
    "ggml_map_custom1": "Applies a custom unary function to a tensor.",
    "ggml_map_custom1_inplace": "Applies a custom unary function to a tensor in-place.",
    "ggml_map_custom2": "Applies a custom binary function to a tensor.",
    "ggml_map_custom2_inplace": "Applies a custom binary function to a tensor in-place.",
    "ggml_map_custom3": "Applies a custom ternary function to a tensor.",
    "ggml_map_custom3_inplace": "Applies a custom ternary function to a tensor in-place.",
    "ggml_cross_entropy_loss": "Computes the cross-entropy loss for a tensor.",
    "ggml_cross_entropy_loss_back": "Computes the backward pass for cross-entropy loss.",
    "ggml_opt_step_adamw": "Performs an optimization step using the AdamW algorithm.",
    "ggml_build_forward_expand": "Builds an expanded forward computation graph.",
    "ggml_build_backward_expand": "Builds an expanded backward computation graph.",
    "ggml_new_graph": "Creates a new computation graph.",
    "ggml_new_graph_custom": "Creates a custom computation graph.",
    "ggml_graph_dup": "Duplicates an existing computation graph.",
    "ggml_graph_cpy": "Copies a computation graph.",
    "ggml_graph_reset": "Resets the state of a computation graph.",
    "ggml_graph_clear": "Clears all nodes from a computation graph.",
    "ggml_graph_size": "Returns the size of a computation graph.",
    "ggml_graph_node": "Retrieves a specific node from a computation graph.",
    "ggml_graph_nodes": "Returns all nodes within a computation graph.",
    "ggml_graph_n_nodes": "Returns the total number of nodes in a computation graph.",
    "ggml_graph_add_node": "Adds a node to a computation graph.",
    "ggml_graph_overhead": "Returns the memory overhead of a computation graph.",
    "ggml_graph_overhead_custom": "Returns custom overhead metrics for a computation graph.",
    "ggml_graph_get_tensor": "Retrieves a tensor from a graph node.",
    "ggml_graph_get_grad": "Retrieves the gradient tensor from a graph node.",
    "ggml_graph_get_grad_acc": "Retrieves the accumulated gradients from a graph node.",
    "ggml_graph_export": "Exports a computation graph to a file or format.",
    "ggml_graph_import": "Imports a computation graph from a file or format.",
    "ggml_graph_print": "Prints a human-readable representation of a computation graph.",
    "ggml_graph_dump_dot": "Dumps the computation graph in DOT format.",
    "ggml_log_set": "Sets the logging level or output for ggml.",
    "ggml_set_zero": "Sets all elements of a tensor to zero.",
    "ggml_quantize_init": "Initializes quantization parameters for tensors.",
    "ggml_quantize_free": "Frees resources used for quantization.",
    "ggml_quantize_requires_imatrix": "Checks if quantization requires an integer matrix.",
    "ggml_quantize_chunk": "Quantizes a chunk of tensor data.",
    "ggml_get_type_traits": "Retrieves type traits for a given tensor type.",
    "ggml_threadpool_params_default": "Returns default parameters for thread pool configuration.",
    "ggml_threadpool_params_init": "Initializes parameters for a thread pool.",
    "ggml_threadpool_params_match": "Checks if two thread pool parameter sets match.",
    "gguf_init_empty": "Initializes an empty GGUF structure.",
    "gguf_init_from_file": "Initializes a GGUF structure from a file.",
    "gguf_free": "Frees a GGUF structure.",
    "gguf_type_name": "Returns the name of a GGUF type.",
    "gguf_get_version": "Retrieves the version of the GGUF format.",
    "gguf_get_alignment": "Returns the alignment requirement for GGUF data.",
    "gguf_get_data_offset": "Retrieves the data offset within a GGUF file.",
    "gguf_get_n_kv": "Returns the number of key-value pairs in a GGUF structure.",
    "gguf_find_key": "Searches for a key within a GGUF structure.",
    "gguf_get_key": "Retrieves a key from a GGUF structure.",
    "gguf_get_kv_type": "Returns the type of a key-value pair in GGUF.",
    "gguf_get_arr_type": "Returns the array type for a GGUF structure.",
    "gguf_get_val_u8": "Retrieves an unsigned 8-bit value from GGUF.",
    "gguf_get_val_i8": "Retrieves a signed 8-bit value from GGUF.",
    "gguf_get_val_u16": "Retrieves an unsigned 16-bit value from GGUF.",
    "gguf_get_val_i16": "Retrieves a signed 16-bit value from GGUF.",
    "gguf_get_val_u32": "Retrieves an unsigned 32-bit value from GGUF.",
    "gguf_get_val_i32": "Retrieves a signed 32-bit value from GGUF.",
    "gguf_get_val_f32": "Retrieves a 32-bit floating-point value from GGUF.",
    "gguf_get_val_u64": "Retrieves an unsigned 64-bit value from GGUF.",
    "gguf_get_val_i64": "Retrieves a signed 64-bit value from GGUF.",
    "gguf_get_val_f64": "Retrieves a 64-bit floating-point value from GGUF.",
    "gguf_get_val_bool": "Retrieves a boolean value from GGUF.",
    "gguf_get_val_str": "Retrieves a string value from GGUF.",
    "gguf_get_val_data": "Retrieves raw data associated with a key in GGUF.",
    "gguf_get_arr_n": "Returns the number of elements in a GGUF array.",
    "gguf_get_arr_data": "Retrieves the data from a GGUF array.",
    "gguf_get_arr_str": "Retrieves an array of strings from GGUF.",
    "gguf_get_n_tensors": "Returns the number of tensors stored in a GGUF file.",
    "gguf_find_tensor": "Searches for a tensor by name in a GGUF structure.",
    "gguf_get_tensor_offset": "Retrieves the data offset for a tensor in GGUF.",
    "gguf_get_tensor_name": "Retrieves the name of a tensor from GGUF.",
    "gguf_get_tensor_type": "Returns the type of a tensor stored in GGUF.",
    "gguf_get_tensor_size": "Returns the size of a tensor in a GGUF file.",
    "gguf_remove_key": "Removes a key-value pair from a GGUF structure.",
    "gguf_set_val_u8": "Sets an unsigned 8-bit value in GGUF.",
    "gguf_set_val_i8": "Sets a signed 8-bit value in GGUF.",
    "gguf_set_val_u16": "Sets an unsigned 16-bit value in GGUF.",
    "gguf_set_val_i16": "Sets a signed 16-bit value in GGUF.",
    "gguf_set_val_u32": "Sets an unsigned 32-bit value in GGUF.",
    "gguf_set_val_i32": "Sets a signed 32-bit value in GGUF.",
    "gguf_set_val_f32": "Sets a 32-bit floating-point value in GGUF.",
    "gguf_set_val_u64": "Sets an unsigned 64-bit value in GGUF.",
    "gguf_set_val_i64": "Sets a signed 64-bit value in GGUF.",
    "gguf_set_val_f64": "Sets a 64-bit floating-point value in GGUF.",
    "gguf_set_val_bool": "Sets a boolean value in GGUF.",
    "gguf_set_val_str": "Sets a string value in GGUF.",
    "gguf_set_arr_data": "Sets the data for an array in GGUF.",
    "gguf_set_arr_str": "Sets an array of strings in GGUF.",
    "gguf_set_kv": "Sets a key-value pair in GGUF.",
    "gguf_add_tensor": "Adds a tensor to a GGUF structure.",
    "gguf_set_tensor_type": "Sets the type for a tensor in GGUF.",
    "gguf_set_tensor_data": "Sets the data for a tensor in GGUF.",
    "gguf_write_to_file": "Writes a GGUF structure to a file.",
    "gguf_get_meta_size": "Returns the size of the metadata in a GGUF file.",
    "gguf_get_meta_data": "Retrieves the metadata from a GGUF file."
  }
  